In linear algebra, the trace of an n''-by-''n square matrix A'' is defined to be the sum of the elements on the main diagonal (the diagonal from the upper left to the lower right) of ''A, i.e.,\mathrm(A) = a_ + a_ + \dots + a_=\sum_^ a_ \,where a_ represents the entry on the i''th row and ''j''th column of ''A. Equivalently, the trace of a matrix is the sum of its eigenvalues, making it an invariant with respect to a change of basis. This characterization can be used to define the trace for a linear operator in general.Note that the trace is only defined for a square matrix (i.e. n''&times;''n).The use of the term trace arises from the German term Spur (cognate with the English spoor), which, as a function in mathematics, is often abbreviated to "Sp".ExamplesLet T be a linear operator represented by the matrix\begin-2&2&-3\\1& 1& 3\\2 &0 &-1\end. Then tr(T)&nbsp;=&nbsp;&minus;2&nbsp;+&nbsp;1&nbsp;&minus;&nbsp;1&nbsp;=&nbsp;&minus;2.The trace of the identity matrix is the dimension of the space. The trace of a nilpotent matrix is zero.If A'' and ''B are positive semi-definite matrices of the same order then 0 \leq \mathrm(AB)^n \leq \mathrm(A)^n \mathrm(B)^n.\,PropertiesThe trace is a linear map. That is,tr(A'' + ''B) = tr(A'') + tr(''B)tr(rA) = r'' tr(''A)for all square matrices A'' and ''B, and all scalars r.If A'' is an ''m&times;n'' matrix and ''B is an n''&times;''m matrix, thentr(AB) = tr(BA).This is immediate from the definition of matrix multiplication.\mathrm(AB) = \sum_^m \sum_^n A_ B_ = \mathrm(BA).Conversely, the above properties characterize the trace completely in the sense as follows. Let f be a linear functional on the space of square matrices satisfying f(xy) = f(yx). Then f and tr are proportional, forf(e_) = 0 if and only if i \not= j and f(e_) = f(e_) (with the standard basis e_),and thusf(A) = \sum_ A_ f(e_) = \sum_i A_ f(e_) = f(e_) \operatorname(A).When both A'' and ''B are n'' by ''n, the trace vanishes on the derived algebra: tr([A'',''B]) = 0, and the trace gives a map of Lie algebras \mathfrak_ \to k (where k is the scalar field, with the commutative Lie algebra structure).The trace is similarity-invariant, which means that A'' and ''P&minus;1AP have the same trace.since\operatorname(P^AP) = \operatorname((AP) P^) = \operatorname(A)A matrix and its transposition have the same trace:tr(A'') = tr(''AT).Let A'', ''B, C be square matrices of the same size. Then\operatorname(ABC) = \operatorname(CAB) = \operatorname(BCA).\,However, even if A'', ''B, and C are square matrices of the same dimension, then the traces of their products do depend on the order of the product; i.e., not all permutations of the three letters are allowed. An example would beA = \left(\begin1&0\\1&0\end\right)\qquad B = \left(\begin2&1\\1&0\end\right)\qquad C = \left(\begin0&2\\1&1\end\right). Then \mathrm(ABC)=\mathrm\left(\begin1&5\\1&5\end\right)=6 and \mathrm(BAC)=\mathrm\left(\begin0&6\\0&2\end\right)=2.For four or more matrices, any cyclic permutation is allowed; thus, for example, tr(ABCDE) = tr(EABCD).However, if products of three symmetric matrices are considered, any permutation is allowed. (Proof: tr(ABC) = tr(AT BT CT) = tr((CBA)T) = tr(CBA).) For more than three factors this is not true.This is known as the cyclic property.Given some linear map f'' : ''V &rarr; V'' (''V is a finite-dimensional vector space) generally, we can define the trace of this map by considering the trace of matrix representation of f'', that is, choosing a basis for ''V and describing f as a matrix relative to this basis, and taking the trace of this square matrix. The result will not depend on the basis chosen, since different bases will give rise to similar matrices, allowing for the possibility of a basis independent definition for the trace of a linear map.Such a definition can be given using the canonical isomorphism between the space End(V'') of linear maps on ''V and V''&otimes;''V*, where V''* is the dual space of ''V. Let v'' be in ''V and let f'' be in ''V*. Then the trace of the decomposable element v''&otimes;''f is defined to be f''(''v); the trace of a general element is defined by linearity. Using an explicit basis for V'' and the corresponding dual basis for ''V*, one can show that this gives the same definition of the trace as given above.Eigenvalue relationshipsIf A'' is a square ''n-by-''n'' matrix with real or complex entries and if &lambda;1,...,&lambda;n'' are the (complex and distinct) eigenvalues of ''A (listed according to their algebraic multiplicities), then\operatornameA = \sum \lambda_i.This follows from the fact that A'' is always similar to its Jordan form, an upper triangular matrix having &lambda;1,...,&lambda;''n on the main diagonal. In contrast, the determinant of A is the product of its eigenvalues; i.e.,\operatornameA = \prod \lambda_iDerivativesThe trace is the derivative of the determinant: it is the Lie algebra analog of the (Lie group) map of the determinant. This is made precise in Jacobi's formula for the derivative of the determinant (see under determinant). As a particular case, \operatorname=\operatorname'_I: the trace is the derivative of the determinant at the identity. From this (or from the connection between the trace and the eigenvalues), one can derive a connection between the trace function, the exponential map between a Lie algebra and its Lie group (or concretely, the matrix exponential function), and the determinant:det(exp(A'')) = exp(tr(''A)).For example, consider the one-parameter family of linear transformations given by rotation through angle θ,R_ = \left(\begin\cos \theta & -\sin \theta\\\sin \theta&\cos \theta\end\right)These transformations all have determinant 1, so they preserve area. The derivative of this family at θ = 0 is the antisymmetric matrixA = \left(\begin0 & -1\\1&0\end\right)which clearly has trace zero, indicating that this matrix represents an infinitesimal transformation which preserves area.A related characterization of the trace applies to linear vector fields. Given a matrix A'', define a vector field '''F' on R'''n by '''F(x''') = ''Ax'. The components of this vector field are all linear functions (given by the rows of A''). The divergence div '''F' is a constant function, whose value is equal to tr(A). By the divergence theorem, one can interpret this in terms of flows: if F'('x) represents the velocity of a fluid at the location x', and ''U is a region in '''Rn'', the net flow of the fluid out of ''U is given by tr(A'')&middot; vol(''U), where vol(U'') is the volume of ''U.The trace is a linear operator, hence its derivative is constant:   (  ) = ( )ApplicationsThe trace is used to define characters of group representations. Two representations, A''(''x) and B''(''x), are equivalent if tr A''(''x) = tr B''(''x).The trace also plays a central role in the distribution of quadratic forms.Lie algebraA matrix whose trace is zero is said to be traceless or tracefree, and these matrices form the simple Lie algebra sln'', which is the Lie algebra of the special linear group of matrices with determinant 1. The special linear group consists of the matrices which do not change volume, while the special linear algebra is the matrices which ''infinitesimally do not change volume.The bilinear formB(x, y) = \operatorname(\operatorname(x)\operatorname(y)) where \operatorname(x)y = xy - yxis called the Killing form, which is used for the classification of Lie algebras.Inner productFor an m''-by-''n matrix A with complex (or real) entries and * being the conjugate transpose, we havetr(A''*''A) &ge; 0with equality only if A = 0. The assignment\langle A, B\rangle = \operatorname(A^*B)yields an inner product on the space of all complex (or real) m''-by-''n matrices.If m''=''n then the norm induced by the above inner product is called the Frobenius norm of a square matrix. Indeed it is simply the Euclidean norm if the matrix is considered as a vector of length n2.GeneralizationThe concept of trace of a matrix is generalised to the trace class of compact operators on Hilbert spaces, and the analog of the Frobenius norm is called the Hilbert-Schmidt norm.The partial trace is another generalization of the trace that is operator-valued.If A'' is a general associative algebra over a field ''k, then a trace on A'' is often defined to be any map tr: ''A &rarr; k'' which vanishes on commutators: tr([''a,b'']) = 0 for all ''a,b'' in ''A. Such a trace is not uniquely defined; it can always at least be modified by multiplication by a nonzero scalar.A supertrace is the generalization of a trace to the setting of superalgebras.The operation of tensor contraction generalizes the trace to arbitrary tensors.Coordinate-Free DefinitionWe can identify the space of linear operators on a vector space V with the space V \otimes V^*, where v \otimes w, v \in V, w \in V^* is the function that consists of application of w to get a scalar followed by multiplication by v. We also have a canonical bilinear function t:V \times V^* \rightarrow F that consists of applying said element of V^* to said element of V to get an element of F. This induces a linear function on the tensor product (by its universal property), which, as it turns out, when that tensor product is viewed as the space of operators, is equal to the trace.For V finite-dimensional, with basis \ and dual basis \, then e_i \otimes e^j is the ij entry of the matrix of the operator with respect to that basis, so we can write any operator as a sum of these. Notice that e_i \otimes e^j maps to 1 iff i=j and 0 otherwise under the trace operator, and from this it's not too hard to see that this coordinate-free definition corresponds to the 'high-school' definition of trace.See alsotrace classfield traceGolden-Thompson inequalitycharacteristic functionReferencesCategory:Linear algebra Category:Matrix theorycs:Stopa (algebra) de:Spur (Mathematik) es:Traza de una matriz eo:Spuro (lineara algebro) fr:Trace (algèbre) ko:대각합 it:Traccia (matrice) he:עקבה (אלגברה) nl:Spoor (wiskunde) ja:跡 (線型代数学) pl:Ślad macierzy pt:Traço (álgebra linear) ru:След матрицы fi:Jälki sv:Spår (matematik) th:รอยเมทริกซ์ uk:Слід матриці zh:跡數